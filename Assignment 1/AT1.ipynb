{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bc3a6b-35ae-402c-a543-531fdad9525c",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe134a8-d551-4d1c-b057-8b409fad25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-read-all-csv-files-in-a-folder-in-pandas/\n",
    "# https://stackoverflow.com/questions/8369219/how-can-i-read-a-text-file-into-a-string-variable-and-strip-newlines\n",
    "# https://stackoverflow.com/questions/10715965/create-a-pandas-dataframe-by-appending-one-row-at-a-time/10716007#10716007\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# use glob to get all the txt files in the folder \n",
    "path = os.getcwd() + '\\\\Datasets'\n",
    "# added -plain to avoid the text description\n",
    "text_files = glob.glob(os.path.join(path, \"*-plain.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96978255-29ca-4967-8a54-ad19c7a4907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_row(df, row):\n",
    "    return pd.concat([\n",
    "                df, \n",
    "                pd.DataFrame([row], columns=row.index)]\n",
    "           ).reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(columns=('lib', 'qty1', 'qty2'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "277f8ad7-60ff-4acb-874b-cbbc5a6febca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a dataframe\n",
    "df = pd.DataFrame(columns=['Station', 'Text'])\n",
    "\n",
    "for file in text_files:\n",
    "    # Get the radio station\n",
    "    radio_station = file.split('\\\\Datasets\\\\')[1].split('-plain.txt')[0][:-1]\n",
    "\n",
    "    # Get the text data\n",
    "    with open(file, 'r') as f:\n",
    "        text = f.read().replace('\\n', ' ')\n",
    "\n",
    "    # Declare a new row to append\n",
    "    new_row = pd.Series({\n",
    "        'Station':radio_station,\n",
    "        'Text':text,\n",
    "    })\n",
    "\n",
    "    # Save text into dataframe\n",
    "    df = append_row(df, new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "464195b9-d4a5-4eaf-b5a5-631e4bd38a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Ah look l Les Pete. .  Simon.  G'day Peto.  S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.  Good afte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.  G'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME</td>\n",
       "      <td>Morning Mark.   Uh uh good morning John. Um t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station                                               Text\n",
       "0    ABCE   Thanks for that John Hall now John Hall will ...\n",
       "1    ABCE   Ah look l Les Pete. .  Simon.  G'day Peto.  S...\n",
       "2    ABCE   If you haven't been with us before this how i...\n",
       "3    ABCE   Uh blue-tongues'd be  unlikely to eat them be...\n",
       "4   ABCNE   A very good afternoon to you Roly.  Good afte...\n",
       "5   ABCNE   And Greg Kerrin is my guest. Hello Greg.  G'd...\n",
       "6    COME   Good morning and welcome to another Two G B w...\n",
       "7    COME   Good morning everyone and welcome to a very f...\n",
       "8    COME   The doctor is in the lines are open one-three...\n",
       "9    COME   Morning Mark.   Uh uh good morning John. Um t..."
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify correct loading of data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34b0c0c4-31c1-41c5-b32c-81af6fa1e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some notes...\n",
    "# Already can see some australian slang - G'day appears in a few text files already\n",
    "# Much more casual language sometimes\n",
    "# Data is unbalanced - some stations more represented than others - how to deal with it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe491b8-23e0-4ceb-91b0-b1c7b726a868",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n",
    "Goals\n",
    "- Find the most common word used in the text to find topic\n",
    "    - May have to use bigrams or trigrams if a topic is something like \"solar energy\" or \"nuclear waste\"\n",
    "    - decisions will be made after this test\n",
    "- Current pipeline\n",
    "    - remove punctuation\n",
    "    - remove numerics\n",
    "    - all text to lowercase\n",
    "    - remove stopwords\n",
    "    - remove extra whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe551233-bd4d-46ed-8b37-c029fddea199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from week 2 lab\n",
    "# We create a TextPreprocessor class that encapsulates all the preprocessing steps. The class constructor allows for custom punctuation marks and stopwords to be added.\n",
    "# Each preprocessing step is implemented as a separate method so we can define in which order they need to be called.\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK data - already downloaded, commented to clean output a bit\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "class TextPreprocessor:\n",
    "    def __init__(self, custom_punctuation=None, custom_stopwords=None):\n",
    "        self.punctuation = string.punctuation\n",
    "        if custom_punctuation:\n",
    "            self.punctuation += custom_punctuation\n",
    "\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        if custom_stopwords:\n",
    "            self.stop_words.update(custom_stopwords)\n",
    "\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        return ''.join([char for char in text if char not in self.punctuation])\n",
    "\n",
    "    # Custom one for the CNN dataset - try removing below and see results\n",
    "    def add_space_after_parenthesis(self, text):\n",
    "        return re.sub(r'\\)', ') ', text)\n",
    "\n",
    "    def to_lowercase(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([word for word in words if word not in self.stop_words])\n",
    "\n",
    "    def remove_extra_whitespace(self, text): # This is to remove our CNN) problem - The space is added before punctuation removal, so it won't affect the final preprocessed text if you're removing all punctuation\n",
    "        return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    def stem_words(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([self.stemmer.stem(word) for word in words])\n",
    "\n",
    "    # Drop the first character(is a 0) and any \\n<numeric>\n",
    "    def remove_numerics(self, text):\n",
    "        return re.sub('\\d*', '', text[1:])\n",
    "\n",
    "    #Order matters - how you call these methods is how the text will be processed step-by-step\n",
    "    # rearrange if we want to change the order of functions here\n",
    "    def preprocess(self, text):\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.remove_numerics(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        #text = self.remove_extra_whitespace(text)\n",
    "        #text = self.add_space_after_parenthesis(text)\n",
    "        #text = self.stem_words(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2e19f6a-cd58-426f-a0f8-cd723eed9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "text_cleaned = preprocessor.preprocess(df.Text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "40e16620-ee6a-4b73-bc0b-7431015cc91a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks john hall john hall listening next hour cos angus stewart take calls eighttriplethreeonethousand oneeighthundredeighthundredsevenohtwo something garden thats causing problems give us call right angus mean yknow known trade mr popergation mr propagation hes also known passion natives love orchids right far guess yeah yeah hes also known ability open cosposting toilets tell anything worm farm problems certainly helped us although im still confused dry ingredients might talk well eighttriple'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "52907586-7bda-40be-a23f-fd18adb4a478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Thanks for that John Hall now John Hall will be listening for the next hour 'cos Angus Stewart is here to take your calls eight-triple-three-one-thousand one-eight-hundred-eight-hundred-seven-oh-two something in the garden that's causing you problems give us a call right now and Angus can I mean y'know he is known in the trade as Mr popergation  Mr propagation. He's also known for his passion for natives and his love of o orchids am I right so far.  I guess yeah yeah .  He's also known  for his\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0176e3c6-e32c-4cda-9259-50e8a6908dec",
   "metadata": {},
   "source": [
    "- hyphens may need to be turned into spaces\n",
    "- 'cos --> because (slang)??? for now leave as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b32508ad-e602-4d60-a76b-960f20e45a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine with a step to change hyphen to spaces\n",
    "# Code cleaned up\n",
    "class TextPreprocessor:\n",
    "    def __init__(self, custom_punctuation=None, custom_stopwords=None):\n",
    "        self.punctuation = string.punctuation\n",
    "        if custom_punctuation:\n",
    "            self.punctuation += custom_punctuation\n",
    "\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        if custom_stopwords:\n",
    "            self.stop_words.update(custom_stopwords)\n",
    "\n",
    "        self.stemmer = PorterStemmer()\n",
    "\n",
    "    def remove_punctuation(self, text):\n",
    "        return ''.join([char for char in text if char not in self.punctuation])\n",
    "\n",
    "    def to_lowercase(self, text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        words = word_tokenize(text)\n",
    "        return ' '.join([word for word in words if word not in self.stop_words])\n",
    "\n",
    "    # Drop the first character(is a 0) and any \\n<numeric>\n",
    "    def remove_numerics(self, text):\n",
    "        return re.sub('\\d*', '', text[1:])\n",
    "\n",
    "    # Change hypen to space\n",
    "    def hyphen_to_space(self, text):\n",
    "        return text.replace('-', ' ')\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        text = self.hyphen_to_space(text)\n",
    "        text = self.remove_punctuation(text)\n",
    "        text = self.remove_numerics(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        text = self.remove_stopwords(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3e3eaefb-67df-4389-86e9-686b01de35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "text_cleaned = preprocessor.preprocess(df.Text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "85b684b8-1ab9-489e-a6ea-a32724a33381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks john hall john hall listening next hour cos angus stewart take calls eight triple three one thousand one eight hundred eight hundred seven oh two something garden thats causing problems give us call right angus mean yknow known trade mr popergation mr propagation hes also known passion natives love orchids right far guess yeah yeah hes also known ability open cosposting toilets tell anything worm farm problems certainly helped us although im still confused dry ingredients might talk well '"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaned[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "28005b6b-9193-4313-9b29-7be74a0efae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "\n",
    "# Add cleaned text to dataframe for later use\n",
    "for index, row in df.iterrows():\n",
    "    processed_text.append(preprocessor.preprocess(row.Text))\n",
    "\n",
    "# Add new column\n",
    "df.insert(2, \"Text_Clean\", processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a6d73dd1-35d3-44c1-853c-ddcaad26ff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "      <td>thanks john hall john hall listening next hour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Ah look l Les Pete. .  Simon.  G'day Peto.  S...</td>\n",
       "      <td>ah look l les pete simon gday peto simo gday l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "      <td>havent us functions jurate sasnaitis joins us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "      <td>uh blue tonguesd unlikely eat good old uh hemi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.  Good afte...</td>\n",
       "      <td>good afternoon roly good afternoon sir mm good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.  G'd...</td>\n",
       "      <td>greg kerrin guest hello greg gday trevor well ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "      <td>good morning welcome another two g b weekend o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "      <td>good morning everyone welcome foggy sort overc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "      <td>doctor lines open one three one eight seven th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME</td>\n",
       "      <td>Morning Mark.   Uh uh good morning John. Um t...</td>\n",
       "      <td>morning mark uh uh good morning john um yeah i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station                                               Text  \\\n",
       "0    ABCE   Thanks for that John Hall now John Hall will ...   \n",
       "1    ABCE   Ah look l Les Pete. .  Simon.  G'day Peto.  S...   \n",
       "2    ABCE   If you haven't been with us before this how i...   \n",
       "3    ABCE   Uh blue-tongues'd be  unlikely to eat them be...   \n",
       "4   ABCNE   A very good afternoon to you Roly.  Good afte...   \n",
       "5   ABCNE   And Greg Kerrin is my guest. Hello Greg.  G'd...   \n",
       "6    COME   Good morning and welcome to another Two G B w...   \n",
       "7    COME   Good morning everyone and welcome to a very f...   \n",
       "8    COME   The doctor is in the lines are open one-three...   \n",
       "9    COME   Morning Mark.   Uh uh good morning John. Um t...   \n",
       "\n",
       "                                          Text_Clean  \n",
       "0  thanks john hall john hall listening next hour...  \n",
       "1  ah look l les pete simon gday peto simo gday l...  \n",
       "2  havent us functions jurate sasnaitis joins us ...  \n",
       "3  uh blue tonguesd unlikely eat good old uh hemi...  \n",
       "4  good afternoon roly good afternoon sir mm good...  \n",
       "5  greg kerrin guest hello greg gday trevor well ...  \n",
       "6  good morning welcome another two g b weekend o...  \n",
       "7  good morning everyone welcome foggy sort overc...  \n",
       "8  doctor lines open one three one eight seven th...  \n",
       "9  morning mark uh uh good morning john um yeah i...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ce5424a4-f7dd-48ab-957e-685d1f0a9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to find the word count\n",
    "\n",
    "def word_count(text):\n",
    "    wc = len(text.split())\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0988ab2b-8f5c-43b2-aa76-27a5328eda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Word_Count'] = df.Text_Clean.apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "51633d33-f529-436f-9d9e-06fe1f0b29e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Text_Word_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "      <td>thanks john hall john hall listening next hour...</td>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Ah look l Les Pete. .  Simon.  G'day Peto.  S...</td>\n",
       "      <td>ah look l les pete simon gday peto simo gday l...</td>\n",
       "      <td>5145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "      <td>havent us functions jurate sasnaitis joins us ...</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "      <td>blue tonguesd unlikely eat good old  hemidact...</td>\n",
       "      <td>1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.  Good afte...</td>\n",
       "      <td>good afternoon roly good afternoon sir mm good...</td>\n",
       "      <td>2433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.  G'd...</td>\n",
       "      <td>greg kerrin guest hello greg gday trevor well ...</td>\n",
       "      <td>2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "      <td>good morning welcome another two g b weekend o...</td>\n",
       "      <td>7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "      <td>good morning everyone welcome foggy sort overc...</td>\n",
       "      <td>3785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "      <td>doctor lines open one three one eight seven th...</td>\n",
       "      <td>6121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME</td>\n",
       "      <td>Morning Mark.   Uh uh good morning John. Um t...</td>\n",
       "      <td>morning mark   good morning john  yeah ive ive...</td>\n",
       "      <td>6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>COME</td>\n",
       "      <td>Here's Sharina's Saturday Nights the positive...</td>\n",
       "      <td>heres sharinas saturday nights positive vibe g...</td>\n",
       "      <td>9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>COME</td>\n",
       "      <td>Where we are talking about how long it takes ...</td>\n",
       "      <td>talking long takes install stuff im little ann...</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COME</td>\n",
       "      <td>Program G P Dr Sally Cockburn good morning.  ...</td>\n",
       "      <td>program g p dr sally cockburn good morning mor...</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>COME</td>\n",
       "      <td>Mix one-oh-six-point-five We Did It All For L...</td>\n",
       "      <td>mix one oh six point five love course love lin...</td>\n",
       "      <td>2051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Freo Dockers skipper there Peter Bell hello e...</td>\n",
       "      <td>freo dockers skipper peter bell hello everyone...</td>\n",
       "      <td>4899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Good afternoon Howard Sattler with you welcom...</td>\n",
       "      <td>good afternoon howard sattler welcome drive pr...</td>\n",
       "      <td>3393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>We are Talking Real Estate on eight-eighty-tw...</td>\n",
       "      <td>talking real estate eight eighty two six p r t...</td>\n",
       "      <td>4192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Thank you Len and a very good morning to a ra...</td>\n",
       "      <td>thank len good morning ravishingly lovely rela...</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Lawyer Bob on the job merry Christmas.  Merry...</td>\n",
       "      <td>lawyer bob job merry christmas merry christmas...</td>\n",
       "      <td>2587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Well the wait ended for year twelve students ...</td>\n",
       "      <td>well wait ended year twelve students today fou...</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COMNE</td>\n",
       "      <td>Been to the city lately tried to find a park ...</td>\n",
       "      <td>city lately tried find park maybe youve gone o...</td>\n",
       "      <td>3119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NAT</td>\n",
       "      <td>One-eight-hundred-eight-oh-two-three-four-one...</td>\n",
       "      <td>one eight hundred eight oh two three four one ...</td>\n",
       "      <td>3277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NAT</td>\n",
       "      <td>And speaking of welcomes and people we love R...</td>\n",
       "      <td>speaking welcomes people love ramona koval wel...</td>\n",
       "      <td>4026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NAT</td>\n",
       "      <td>Good morning how are you.  Ih is it true you'...</td>\n",
       "      <td>good morning ih true youve  australian childre...</td>\n",
       "      <td>4062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NAT</td>\n",
       "      <td>Eighteen minutes past ten eighteen past nine ...</td>\n",
       "      <td>eighteen minutes past ten eighteen past nine q...</td>\n",
       "      <td>10582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NAT</td>\n",
       "      <td>So now it's welcome first to our expert panel...</td>\n",
       "      <td>welcome first expert panel dr brian edgar dire...</td>\n",
       "      <td>3636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NAT</td>\n",
       "      <td>you're with Mel in the morning it's fourteen ...</td>\n",
       "      <td>youre mel morning fourteen eleven means dr kar...</td>\n",
       "      <td>3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NAT</td>\n",
       "      <td>Five A M in New York hey. There's gotta be  s...</td>\n",
       "      <td>five new york hey theres got ta something salt...</td>\n",
       "      <td>3233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NAT</td>\n",
       "      <td>Hello and welcome to the Chatroom with Gaby t...</td>\n",
       "      <td>hello welcome chatroom gaby tonight world refu...</td>\n",
       "      <td>8329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Station                                               Text  \\\n",
       "0     ABCE   Thanks for that John Hall now John Hall will ...   \n",
       "1     ABCE   Ah look l Les Pete. .  Simon.  G'day Peto.  S...   \n",
       "2     ABCE   If you haven't been with us before this how i...   \n",
       "3     ABCE   Uh blue-tongues'd be  unlikely to eat them be...   \n",
       "4    ABCNE   A very good afternoon to you Roly.  Good afte...   \n",
       "5    ABCNE   And Greg Kerrin is my guest. Hello Greg.  G'd...   \n",
       "6     COME   Good morning and welcome to another Two G B w...   \n",
       "7     COME   Good morning everyone and welcome to a very f...   \n",
       "8     COME   The doctor is in the lines are open one-three...   \n",
       "9     COME   Morning Mark.   Uh uh good morning John. Um t...   \n",
       "10    COME   Here's Sharina's Saturday Nights the positive...   \n",
       "11    COME   Where we are talking about how long it takes ...   \n",
       "12    COME   Program G P Dr Sally Cockburn good morning.  ...   \n",
       "13    COME   Mix one-oh-six-point-five We Did It All For L...   \n",
       "14   COMNE   Freo Dockers skipper there Peter Bell hello e...   \n",
       "15   COMNE   Good afternoon Howard Sattler with you welcom...   \n",
       "16   COMNE   We are Talking Real Estate on eight-eighty-tw...   \n",
       "17   COMNE   Thank you Len and a very good morning to a ra...   \n",
       "18   COMNE   Lawyer Bob on the job merry Christmas.  Merry...   \n",
       "19   COMNE   Well the wait ended for year twelve students ...   \n",
       "20   COMNE   Been to the city lately tried to find a park ...   \n",
       "21     NAT   One-eight-hundred-eight-oh-two-three-four-one...   \n",
       "22     NAT   And speaking of welcomes and people we love R...   \n",
       "23     NAT   Good morning how are you.  Ih is it true you'...   \n",
       "24     NAT   Eighteen minutes past ten eighteen past nine ...   \n",
       "25     NAT   So now it's welcome first to our expert panel...   \n",
       "26     NAT   you're with Mel in the morning it's fourteen ...   \n",
       "27     NAT   Five A M in New York hey. There's gotta be  s...   \n",
       "28     NAT   Hello and welcome to the Chatroom with Gaby t...   \n",
       "\n",
       "                                           Text_Clean  Text_Word_Count  \n",
       "0   thanks john hall john hall listening next hour...             4571  \n",
       "1   ah look l les pete simon gday peto simo gday l...             5145  \n",
       "2   havent us functions jurate sasnaitis joins us ...             3100  \n",
       "3    blue tonguesd unlikely eat good old  hemidact...             1794  \n",
       "4   good afternoon roly good afternoon sir mm good...             2433  \n",
       "5   greg kerrin guest hello greg gday trevor well ...             2250  \n",
       "6   good morning welcome another two g b weekend o...             7489  \n",
       "7   good morning everyone welcome foggy sort overc...             3785  \n",
       "8   doctor lines open one three one eight seven th...             6121  \n",
       "9   morning mark   good morning john  yeah ive ive...             6592  \n",
       "10  heres sharinas saturday nights positive vibe g...             9739  \n",
       "11  talking long takes install stuff im little ann...             1640  \n",
       "12  program g p dr sally cockburn good morning mor...             1617  \n",
       "13  mix one oh six point five love course love lin...             2051  \n",
       "14  freo dockers skipper peter bell hello everyone...             4899  \n",
       "15  good afternoon howard sattler welcome drive pr...             3393  \n",
       "16  talking real estate eight eighty two six p r t...             4192  \n",
       "17  thank len good morning ravishingly lovely rela...             7469  \n",
       "18  lawyer bob job merry christmas merry christmas...             2587  \n",
       "19  well wait ended year twelve students today fou...             1807  \n",
       "20  city lately tried find park maybe youve gone o...             3119  \n",
       "21  one eight hundred eight oh two three four one ...             3277  \n",
       "22  speaking welcomes people love ramona koval wel...             4026  \n",
       "23  good morning ih true youve  australian childre...             4062  \n",
       "24  eighteen minutes past ten eighteen past nine q...            10582  \n",
       "25  welcome first expert panel dr brian edgar dire...             3636  \n",
       "26  youre mel morning fourteen eleven means dr kar...             3147  \n",
       "27  five new york hey theres got ta something salt...             3233  \n",
       "28  hello welcome chatroom gaby tonight world refu...             8329  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n",
    "# Not sure if useful, but some texts are longer than others\n",
    "\n",
    "# ABCNE seems to be much shorter than the others\n",
    "# NAT tends to be longer, with 2 very long texts\n",
    "# COME has a very long text, but also a few very short texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5d800aaf-f22a-445b-b665-7dbbc0c72f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most common word\n",
    "from collections import Counter\n",
    "\n",
    "most_common_word = []\n",
    "most_common_word_count = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row.Text_Clean.split()\n",
    "    word_counter = Counter(text)\n",
    "    most_common_word.append(word_counter.most_common()[0])\n",
    "\n",
    "# Add new column\n",
    "df.insert(4, \"Most_Common_Word\", most_common_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "7e22f1f5-e71b-40ab-9893-892f49abeade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Text_Word_Count</th>\n",
       "      <th>Most_Common_Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "      <td>thanks john hall john hall listening next hour...</td>\n",
       "      <td>4571</td>\n",
       "      <td>(well, 93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Ah look l Les Pete. .  Simon.  G'day Peto.  S...</td>\n",
       "      <td>ah look l les pete simon gday peto simo gday l...</td>\n",
       "      <td>5145</td>\n",
       "      <td>(yeah, 89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "      <td>havent us functions jurate sasnaitis joins us ...</td>\n",
       "      <td>3100</td>\n",
       "      <td>(think, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "      <td>blue tonguesd unlikely eat good old  hemidact...</td>\n",
       "      <td>1794</td>\n",
       "      <td>(yeah, 42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.  Good afte...</td>\n",
       "      <td>good afternoon roly good afternoon sir mm good...</td>\n",
       "      <td>2433</td>\n",
       "      <td>(one, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.  G'd...</td>\n",
       "      <td>greg kerrin guest hello greg gday trevor well ...</td>\n",
       "      <td>2250</td>\n",
       "      <td>(okay, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "      <td>good morning welcome another two g b weekend o...</td>\n",
       "      <td>7489</td>\n",
       "      <td>(good, 108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "      <td>good morning everyone welcome foggy sort overc...</td>\n",
       "      <td>3785</td>\n",
       "      <td>(well, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "      <td>doctor lines open one three one eight seven th...</td>\n",
       "      <td>6121</td>\n",
       "      <td>(got, 79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME</td>\n",
       "      <td>Morning Mark.   Uh uh good morning John. Um t...</td>\n",
       "      <td>morning mark   good morning john  yeah ive ive...</td>\n",
       "      <td>6592</td>\n",
       "      <td>(well, 157)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station                                               Text  \\\n",
       "0    ABCE   Thanks for that John Hall now John Hall will ...   \n",
       "1    ABCE   Ah look l Les Pete. .  Simon.  G'day Peto.  S...   \n",
       "2    ABCE   If you haven't been with us before this how i...   \n",
       "3    ABCE   Uh blue-tongues'd be  unlikely to eat them be...   \n",
       "4   ABCNE   A very good afternoon to you Roly.  Good afte...   \n",
       "5   ABCNE   And Greg Kerrin is my guest. Hello Greg.  G'd...   \n",
       "6    COME   Good morning and welcome to another Two G B w...   \n",
       "7    COME   Good morning everyone and welcome to a very f...   \n",
       "8    COME   The doctor is in the lines are open one-three...   \n",
       "9    COME   Morning Mark.   Uh uh good morning John. Um t...   \n",
       "\n",
       "                                          Text_Clean  Text_Word_Count  \\\n",
       "0  thanks john hall john hall listening next hour...             4571   \n",
       "1  ah look l les pete simon gday peto simo gday l...             5145   \n",
       "2  havent us functions jurate sasnaitis joins us ...             3100   \n",
       "3   blue tonguesd unlikely eat good old  hemidact...             1794   \n",
       "4  good afternoon roly good afternoon sir mm good...             2433   \n",
       "5  greg kerrin guest hello greg gday trevor well ...             2250   \n",
       "6  good morning welcome another two g b weekend o...             7489   \n",
       "7  good morning everyone welcome foggy sort overc...             3785   \n",
       "8  doctor lines open one three one eight seven th...             6121   \n",
       "9  morning mark   good morning john  yeah ive ive...             6592   \n",
       "\n",
       "  Most_Common_Word  \n",
       "0       (well, 93)  \n",
       "1       (yeah, 89)  \n",
       "2      (think, 61)  \n",
       "3       (yeah, 42)  \n",
       "4        (one, 33)  \n",
       "5       (okay, 32)  \n",
       "6      (good, 108)  \n",
       "7       (well, 74)  \n",
       "8        (got, 79)  \n",
       "9      (well, 157)  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b238074-681e-464b-a0af-ae9b51bb35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uh.... Not a great most common word, thought it would be removed by stopwords\n",
    "\n",
    "# Remove um, uh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7b43d74e-d8dd-439b-9834-b0d23e4cc4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_um_uh(text):\n",
    "    text_clean = text.replace('um', '')\n",
    "    text_clean = text_clean.replace('uh', '')\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cb639f34-de6c-4417-91b3-7fed84a17219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns created before\n",
    "df = df.drop('Text_Word_Count', axis=1)\n",
    "df = df.drop('Most_Common_Word', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ea7433e0-7f3e-43ba-ba3e-d2d44abd83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Clean'] = df.Text_Clean.apply(remove_um_uh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "456a82de-810e-4873-b56f-b6313bd66b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text_Word_Count'] = df.Text_Clean.apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "9a844e98-376f-40a4-a5a2-c3e9b3ba803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_word = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Text_Clean'].split()\n",
    "    word_count = Counter(text)\n",
    "    most_common_word.append(word_count.most_common()[0])\n",
    "\n",
    "df.insert(4, \"Most_Common_Word\", most_common_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "74d0cfb5-dccc-4361-af46-ca6e7cd6dfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>Text_Word_Count</th>\n",
       "      <th>Most_Common_Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Thanks for that John Hall now John Hall will ...</td>\n",
       "      <td>thanks john hall john hall listening next hour...</td>\n",
       "      <td>4571</td>\n",
       "      <td>(well, 93)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Ah look l Les Pete. .  Simon.  G'day Peto.  S...</td>\n",
       "      <td>ah look l les pete simon gday peto simo gday l...</td>\n",
       "      <td>5145</td>\n",
       "      <td>(yeah, 89)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>If you haven't been with us before this how i...</td>\n",
       "      <td>havent us functions jurate sasnaitis joins us ...</td>\n",
       "      <td>3100</td>\n",
       "      <td>(think, 61)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABCE</td>\n",
       "      <td>Uh blue-tongues'd be  unlikely to eat them be...</td>\n",
       "      <td>blue tonguesd unlikely eat good old  hemidact...</td>\n",
       "      <td>1794</td>\n",
       "      <td>(yeah, 42)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>A very good afternoon to you Roly.  Good afte...</td>\n",
       "      <td>good afternoon roly good afternoon sir mm good...</td>\n",
       "      <td>2433</td>\n",
       "      <td>(one, 33)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABCNE</td>\n",
       "      <td>And Greg Kerrin is my guest. Hello Greg.  G'd...</td>\n",
       "      <td>greg kerrin guest hello greg gday trevor well ...</td>\n",
       "      <td>2250</td>\n",
       "      <td>(okay, 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning and welcome to another Two G B w...</td>\n",
       "      <td>good morning welcome another two g b weekend o...</td>\n",
       "      <td>7489</td>\n",
       "      <td>(good, 108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COME</td>\n",
       "      <td>Good morning everyone and welcome to a very f...</td>\n",
       "      <td>good morning everyone welcome foggy sort overc...</td>\n",
       "      <td>3785</td>\n",
       "      <td>(well, 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COME</td>\n",
       "      <td>The doctor is in the lines are open one-three...</td>\n",
       "      <td>doctor lines open one three one eight seven th...</td>\n",
       "      <td>6121</td>\n",
       "      <td>(got, 79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COME</td>\n",
       "      <td>Morning Mark.   Uh uh good morning John. Um t...</td>\n",
       "      <td>morning mark   good morning john  yeah ive ive...</td>\n",
       "      <td>6592</td>\n",
       "      <td>(well, 157)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station                                               Text  \\\n",
       "0    ABCE   Thanks for that John Hall now John Hall will ...   \n",
       "1    ABCE   Ah look l Les Pete. .  Simon.  G'day Peto.  S...   \n",
       "2    ABCE   If you haven't been with us before this how i...   \n",
       "3    ABCE   Uh blue-tongues'd be  unlikely to eat them be...   \n",
       "4   ABCNE   A very good afternoon to you Roly.  Good afte...   \n",
       "5   ABCNE   And Greg Kerrin is my guest. Hello Greg.  G'd...   \n",
       "6    COME   Good morning and welcome to another Two G B w...   \n",
       "7    COME   Good morning everyone and welcome to a very f...   \n",
       "8    COME   The doctor is in the lines are open one-three...   \n",
       "9    COME   Morning Mark.   Uh uh good morning John. Um t...   \n",
       "\n",
       "                                          Text_Clean  Text_Word_Count  \\\n",
       "0  thanks john hall john hall listening next hour...             4571   \n",
       "1  ah look l les pete simon gday peto simo gday l...             5145   \n",
       "2  havent us functions jurate sasnaitis joins us ...             3100   \n",
       "3   blue tonguesd unlikely eat good old  hemidact...             1794   \n",
       "4  good afternoon roly good afternoon sir mm good...             2433   \n",
       "5  greg kerrin guest hello greg gday trevor well ...             2250   \n",
       "6  good morning welcome another two g b weekend o...             7489   \n",
       "7  good morning everyone welcome foggy sort overc...             3785   \n",
       "8  doctor lines open one three one eight seven th...             6121   \n",
       "9  morning mark   good morning john  yeah ive ive...             6592   \n",
       "\n",
       "  Most_Common_Word  \n",
       "0       (well, 93)  \n",
       "1       (yeah, 89)  \n",
       "2      (think, 61)  \n",
       "3       (yeah, 42)  \n",
       "4        (one, 33)  \n",
       "5       (okay, 32)  \n",
       "6      (good, 108)  \n",
       "7       (well, 74)  \n",
       "8        (got, 79)  \n",
       "9      (well, 157)  "
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "469d2377-df05-4c4a-86c0-66276cb2131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not work very well, try bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9e9df-7de1-4d57-99fb-94cb3317975a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
